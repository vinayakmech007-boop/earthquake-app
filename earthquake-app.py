import os
import time
from datetime import date, datetime, time as dtime

import requests
import pandas as pd
import streamlit as st
import altair as alt
from concurrent.futures import ThreadPoolExecutor

# ---------------------------------
# âœ… Streamlit page config
# ---------------------------------
st.set_page_config(page_title="NSE Live Turnover Tracker", layout="wide")
st.title("ğŸ“ˆ NSE Live Turnover Tracker (With 20â€‘Day History)")

# ---------------------------------
# âœ… Your stock list
# ---------------------------------
stocks = [
    "RELIANCE", "TCS", "HDFCBANK", "INFY", "ICICIBANK",
    "SBIN", "BHARTIARTL", "KOTAKBANK", "LT", "ITC",
]

# ---------------------------------
# âœ… History file config
# ---------------------------------
HISTORY_FILE = "data/history.csv"
FLAG_FILE = "data/last_store.txt"


# ---------------------------------
# âœ… Helper: Check if today's snapshot is saved
# ---------------------------------
def is_today_saved():
    today_str = date.today().strftime("%Y-%m-%d")
    if os.path.exists(FLAG_FILE):
        with open(FLAG_FILE, "r") as f:
            return f.read().strip() == today_str
    return False


# ---------------------------------
# âœ… Helper: Should store missed 3:30 PM snapshot?
# ---------------------------------
def should_store_if_missed():
    now = datetime.now()
    today_str = now.strftime("%Y-%m-%d")

    # Already saved today?
    if is_today_saved():
        return False

    # If time is AFTER 3:30 PM â†’ store once
    if now.time() >= dtime(15, 30):
        os.makedirs("data", exist_ok=True)
        with open(FLAG_FILE, "w") as f:
            f.write(today_str)
        return True

    return False


# ---------------------------------
# âœ… Stable NSE fetcher (replaces nse_quote_ltp)
# ---------------------------------
def fetch_single(symbol: str) -> dict:
    """
    Fetch live data for a single NSE symbol using official JSON API.
    Includes session, headers, cookies and retry logic.
    """
    base_url = "https://www.nseindia.com"
    quote_url = f"{base_url}/api/quote-equity?symbol={symbol}"

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept": "application/json,text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Referer": f"{base_url}/get-quotes/equity?symbol={symbol}",
    }

    session = requests.Session()

    # âœ… Step 1: Get cookies from homepage (required by NSE)
    try:
        session.get(base_url, headers=headers, timeout=5)
    except Exception:
        # Even if this fails, we still attempt the quote API
        pass

    # âœ… Step 2: Try multiple times to fetch data
    last_error = None
    for _ in range(3):
        try:
            r = session.get(quote_url, headers=headers, timeout=7)
            r.raise_for_status()
            data = r.json()

            price_info = data.get("priceInfo", {}) or {}

            current_price = price_info.get("lastPrice", None)
            previous_close = price_info.get("previousClose", None)
            volume = price_info.get("totalTradedVolume", None)

            percent_change = None
            if current_price is not None and previous_close not in (None, 0):
                percent_change = ((current_price - previous_close) / previous_close) * 100

            value_cr = None
            if current_price is not None and volume is not None:
                # 1 Cr = 10,000,000
                value_cr = (current_price * volume) / 10000000

            return {
                "Symbol": symbol,
                "Current Price": current_price,
                "Previous Close": previous_close,
                "Percent Change (%)": round(percent_change, 2) if percent_change is not None else None,
                "Volume": volume,
                "Value (Cr)": round(value_cr, 2) if value_cr is not None else None,
            }

        except Exception as e:
            last_error = str(e)
            time.sleep(0.7)

    # âœ… If all retries fail
    return {
        "Symbol": symbol,
        "Current Price": None,
        "Previous Close": None,
        "Percent Change (%)": None,
        "Volume": None,
        "Value (Cr)": None,
        "Error": last_error or "Failed to fetch",
    }


# ---------------------------------
# âœ… Fetch all data (parallel + cache)
# ---------------------------------
@st.cache_data(show_spinner=True, ttl=10)
def fetch_data(symbols):
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(fetch_single, symbols))
    df = pd.DataFrame(results)

    # If everything failed, don't cache the bad result
    if df["Current Price"].isna().all():
        # Clear and raise so Streamlit shows something is wrong
        fetch_data.clear()
    return df


# ---------------------------------
# âœ… History helpers
# ---------------------------------
def save_daily_history(df: pd.DataFrame):
    df_to_save = df.copy()
    df_to_save["Date"] = date.today()

    os.makedirs("data", exist_ok=True)

    if os.path.exists(HISTORY_FILE):
        df_to_save.to_csv(HISTORY_FILE, mode="a", header=False, index=False)
    else:
        df_to_save.to_csv(HISTORY_FILE, index=False)


def load_history() -> pd.DataFrame:
    if not os.path.exists(HISTORY_FILE):
        return pd.DataFrame()

    df_hist = pd.read_csv(HISTORY_FILE)

    if "Date" not in df_hist.columns:
        return pd.DataFrame()

    df_hist["Date"] = pd.to_datetime(df_hist["Date"])
    if df_hist["Date"].empty:
        return pd.DataFrame()

    cutoff = df_hist["Date"].max() - pd.Timedelta(days=20)
    df_hist = df_hist[df_hist["Date"] >= cutoff]

    return df_hist


# ---------------------------------
# âœ… Top control bar
# ---------------------------------
col1, col2, col3 = st.columns([2, 1, 1])

with col1:
    st.caption("Live NSE turnover with 20â€‘day average comparison")

with col2:
    refresh_clicked = st.button("ğŸ”„ Refresh Now")

with col3:
    view_mode = st.selectbox(
        "View mode",
        ["All", "Top Turnover vs Avg (High)", "Top Turnover vs Avg (Low)"],
        index=0,
    )

if refresh_clicked:
    fetch_data.clear()


# ---------------------------------
# âœ… Fetch live data
# ---------------------------------
df = fetch_data(stocks)

# âœ… Auto-store missed 3:30 PM snapshot
if should_store_if_missed():
    save_daily_history(df)
    st.success("âœ… Stored missed 3:30 PM snapshot (system was offline earlier)")


# âœ… UI indicator for today's snapshot
if is_today_saved():
    st.success("âœ… Today's 3:30 PM snapshot is saved")
else:
    st.warning("âš ï¸ Today's 3:30 PM snapshot is NOT saved yet")

st.caption(f"Last updated: {datetime.now().strftime('%d-%m-%Y %H:%M:%S')}")


# ---------------------------------
# âœ… Load history and compute 20â€‘day turnover average
# ---------------------------------
history_df = load_history()

if history_df.empty:
    st.warning("Not enough history yet. Data will build over the next 20 days.")
    st.dataframe(df, use_container_width=True)

else:
    avg_turnover = (
        history_df.groupby("Symbol")["Value (Cr)"]
        .mean()
        .reset_index()
        .rename(columns={"Value (Cr)": "Avg 20D Turnover (Cr)"})
    )

    comparison_df = df.merge(avg_turnover, on="Symbol", how="left")

    comparison_df["Turnover vs Avg (%)"] = (
        (comparison_df["Value (Cr)"] - comparison_df["Avg 20D Turnover (Cr)"])
        / comparison_df["Avg 20D Turnover (Cr)"]
    ) * 100

    comparison_df["TradingView"] = comparison_df["Symbol"].apply(
        lambda s: f'<a href="https://www.tradingview.com/chart/?symbol=NSE:{s}" target="_blank">ğŸ“ˆ Chart</a>'
    )

    df_view = comparison_df.copy()

    if view_mode == "Top Turnover vs Avg (High)":
        df_view = df_view.sort_values("Turnover vs Avg (%)", ascending=False)
    elif view_mode == "Top Turnover vs Avg (Low)":
        df_view = df_view.sort_values("Turnover vs Avg (%)", ascending=True)
    else:
        df_view = df_view.sort_values("Symbol")

    st.subheader("ğŸ“ˆ Today vs 20â€‘Day Average Turnover (Vertical Layout)")

    chart_df = df_view[["Symbol", "Value (Cr)", "Avg 20D Turnover (Cr)"]].dropna()

    if not chart_df.empty:
        chart_long = chart_df.melt("Symbol", var_name="Type", value_name="Turnover")

        chart = (
            alt.Chart(chart_long)
            .mark_bar()
            .encode(
                y=alt.Y("Symbol:N", sort="-x", title="Stock Symbol"),
                x=alt.X("Turnover:Q", title="Turnover (Cr)"),
                color=alt.Color(
                    "Type:N",
                    scale=alt.Scale(range=["#4CAF50", "#2196F3"]),
                    title=""
                ),
                tooltip=["Symbol", "Type", "Turnover"],
            )
            .properties(
                width="container",
                height=30 * len(chart_df) if len(chart_df) > 0 else 400,
            )
        )

        st.altair_chart(chart, use_container_width=True)
    else:
        st.info("No valid turnover data available to plot.")

    st.subheader("ğŸ“Š Turnover vs 20â€‘Day Average + TradingView")

    table_cols = [
        "Symbol",
        "Current Price",
        "Percent Change (%)",
        "Volume",
        "Value (Cr)",
        "Avg 20D Turnover (Cr)",
        "Turnover vs Avg (%)",
        "TradingView",
    ]

    st.write(
        df_view[table_cols].to_html(escape=False, index=False),
        unsafe_allow_html=True,
    )

    with st.expander("ğŸ“… Raw 20â€‘Day History (debug/analysis)"):
        st.dataframe(history_df, use_container_width=True)


# ---------------------------------
# âœ… View older history (beyond 20 days)
# ---------------------------------
with st.expander("ğŸ“œ View Older History (Beyond 20 Days)"):
    if os.path.exists(HISTORY_FILE):
        full_hist = pd.read_csv(HISTORY_FILE)
        st.dataframe(full_hist, use_container_width=True)

        csv_data = full_hist.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="â¬‡ï¸ Download Full History CSV",
            data=csv_data,
            file_name="full_history.csv",
            mime="text/csv"
        )
    else:
        st.info("No history file found.")
